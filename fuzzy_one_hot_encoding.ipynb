{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/acc48668/Downloads/fuzzy_matching\n"
     ]
    }
   ],
   "source": [
    "cd Downloads/fuzzy_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaro version\n",
    "def sort_token_alphabetically(word):\n",
    "    token = re.split('[,. ]', word)\n",
    "    sorted_token = sorted(token)\n",
    "    return ' '.join(sorted_token)\n",
    "\n",
    "def get_jaro_distance(first, second, winkler=True, winkler_ajustment=True,\n",
    "                      scaling=0.1, sort_tokens=True):\n",
    "    \"\"\"\n",
    "    :param first: word to calculate distance for\n",
    "    :param second: word to calculate distance with\n",
    "    :param winkler: same as winkler_ajustment\n",
    "    :param winkler_ajustment: add an adjustment factor to the Jaro of the distance\n",
    "    :param scaling: scaling factor for the Winkler adjustment\n",
    "    :return: Jaro distance adjusted (or not)\n",
    "    \"\"\"\n",
    "    if sort_tokens:\n",
    "        first = sort_token_alphabetically(first)\n",
    "        second = sort_token_alphabetically(second)\n",
    "\n",
    "    if not first or not second:\n",
    "        raise JaroDistanceException(\n",
    "            \"Cannot calculate distance from NoneType ({0}, {1})\".format(\n",
    "                first.__class__.__name__,\n",
    "                second.__class__.__name__))\n",
    "\n",
    "    jaro = _score(first, second)\n",
    "    cl = min(len(_get_prefix(first, second)), 4)\n",
    "\n",
    "    if all([winkler, winkler_ajustment]):  # 0.1 as scaling factor\n",
    "        return round((jaro + (scaling * cl * (1.0 - jaro))) * 100.0) / 100.0\n",
    "\n",
    "    return jaro\n",
    "\n",
    "def _score(first, second):\n",
    "    shorter, longer = first.lower(), second.lower()\n",
    "\n",
    "    if len(first) > len(second):\n",
    "        longer, shorter = shorter, longer\n",
    "\n",
    "    m1 = _get_matching_characters(shorter, longer)\n",
    "    m2 = _get_matching_characters(longer, shorter)\n",
    "\n",
    "    if len(m1) == 0 or len(m2) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (float(len(m1)) / len(shorter) +\n",
    "            float(len(m2)) / len(longer) +\n",
    "            float(len(m1) - _transpositions(m1, m2)) / len(m1)) / 3.0\n",
    "\n",
    "def _get_diff_index(first, second):\n",
    "    if first == second:\n",
    "        pass\n",
    "\n",
    "    if not first or not second:\n",
    "        return 0\n",
    "\n",
    "    max_len = min(len(first), len(second))\n",
    "    for i in range(0, max_len):\n",
    "        if not first[i] == second[i]:\n",
    "            return i\n",
    "\n",
    "    return max_len\n",
    "\n",
    "def _get_prefix(first, second):\n",
    "    if not first or not second:\n",
    "        return \"\"\n",
    "\n",
    "    index = _get_diff_index(first, second)\n",
    "    if index == -1:\n",
    "        return first\n",
    "\n",
    "    elif index == 0:\n",
    "        return \"\"\n",
    "\n",
    "    else:\n",
    "        return first[0:index]\n",
    "\n",
    "def _get_matching_characters(first, second):\n",
    "    common = []\n",
    "    limit = math.floor(min(len(first), len(second)) / 2)\n",
    "\n",
    "    for i, l in enumerate(first):\n",
    "        left, right = int(max(0, i - limit)), int(\n",
    "            min(i + limit + 1, len(second)))\n",
    "        if l in second[left:right]:\n",
    "            common.append(l)\n",
    "            second = second[0:second.index(l)] + '*' + second[\n",
    "                                                       second.index(l) + 1:]\n",
    "\n",
    "    return ''.join(common)\n",
    "\n",
    "def _transpositions(first, second):\n",
    "    return math.floor(\n",
    "        len([(f, s) for f, s in zip(first, second) if not f == s]) / 2.0)\n",
    "\n",
    "def get_top_matches(reference, value_list, max_results=None):\n",
    "    scores = []\n",
    "    if not max_results:\n",
    "        max_results = len(value_list)\n",
    "    for val in value_list:\n",
    "        score_sorted = get_jaro_distance(reference, val)\n",
    "        score_unsorted = get_jaro_distance(reference, val, sort_tokens=False)\n",
    "        scores.append((val, max(score_sorted, score_unsorted)))\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return scores[:max_results]\n",
    "\n",
    "class JaroDistanceException(Exception):\n",
    "    def __init__(self, message):\n",
    "        super(Exception, self).__init__(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_org_name</th>\n",
       "      <th>children_org_name_list</th>\n",
       "      <th>match_confidence_score</th>\n",
       "      <th>match_confidence</th>\n",
       "      <th>jaro_func_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+MARTINS</td>\n",
       "      <td>[SAN MARINA]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111 SOUTH</td>\n",
       "      <td>[1&amp;1 IONOS]</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>247 CUSTOMER PVT. LTD.</td>\n",
       "      <td>[24/7 CUSTOMER PRIVATE LIMITED]</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3M</td>\n",
       "      <td>[3M]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>A. K. ENTERPRISE</td>\n",
       "      <td>[ROUSH ENTERPRISE]</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           parent_org_name           children_org_name_list  \\\n",
       "3                 +MARTINS                     [SAN MARINA]   \n",
       "8                111 SOUTH                      [1&1 IONOS]   \n",
       "13  247 CUSTOMER PVT. LTD.  [24/7 CUSTOMER PRIVATE LIMITED]   \n",
       "18                      3M                             [3M]   \n",
       "57        A. K. ENTERPRISE               [ROUSH ENTERPRISE]   \n",
       "\n",
       "    match_confidence_score match_confidence  jaro_func_score  \n",
       "3                 0.750000           MEDIUM             0.78  \n",
       "8                 0.769231           MEDIUM             0.67  \n",
       "13                0.843750           MEDIUM             0.89  \n",
       "18                1.000000             HIGH             1.00  \n",
       "57                0.812500           MEDIUM             0.79  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load csv\n",
    "df = pd.read_csv('bo_attr_lookup_new.csv', encoding='latin1')\n",
    "df = df.dropna()\n",
    "\n",
    "#conver child col to list\n",
    "df['children_org_name_list'] = df['children_org_name_list'].map(lambda x: [x])\n",
    "\n",
    "#jaro score\n",
    "df['jaro_func_score'] = df[['parent_org_name', 'children_org_name_list']].agg(lambda x: get_top_matches(*x), axis=1)\n",
    "df['jaro_func_score'] = df.jaro_func_score.apply(lambda x: [val[1] for val in x])\n",
    "df['jaro_func_score'] = df.jaro_func_score.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "\n",
    "#create df of just medium and high\n",
    "df1 = df[df['match_confidence'].isin(['MEDIUM','HIGH'])]\n",
    "\n",
    "#create low df\n",
    "df2 = df[df['match_confidence'] == 'LOW']\n",
    "\n",
    "#create sample of 2k rows of low df\n",
    "df2 = df2.sample(2000)\n",
    "\n",
    "#concat dfs\n",
    "frames = [df1,df2]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_org_name</th>\n",
       "      <th>children_org_name_list</th>\n",
       "      <th>match_confidence_score</th>\n",
       "      <th>match_confidence</th>\n",
       "      <th>jaro_func_score</th>\n",
       "      <th>total_chars_positions</th>\n",
       "      <th>consecutive_chars</th>\n",
       "      <th>sequence_matcher_ratio</th>\n",
       "      <th>count_same_position</th>\n",
       "      <th>count_total_unique_chars</th>\n",
       "      <th>count_common_chars</th>\n",
       "      <th>percent_matched</th>\n",
       "      <th>percent_same_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+MARTINS</td>\n",
       "      <td>[SAN MARINA]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.78</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111 SOUTH</td>\n",
       "      <td>[1&amp;1 IONOS]</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>247 CUSTOMER PVT. LTD.</td>\n",
       "      <td>[24/7 CUSTOMER PRIVATE LIMITED]</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.89</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3M</td>\n",
       "      <td>[3M]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>A. K. ENTERPRISE</td>\n",
       "      <td>[ROUSH ENTERPRISE]</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.79</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>A.B. EDWARDS ENTERPRISES</td>\n",
       "      <td>[A. G. EDWARDS &amp; SONS]</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.73</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>AAP CO. LTD.</td>\n",
       "      <td>[AAP LEHRERFACHVERLAGE]</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.73</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ABB</td>\n",
       "      <td>[ABBVIE]</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ABBVIE</td>\n",
       "      <td>[ABBVIE]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ABERCROMBIE FITCH</td>\n",
       "      <td>[ABERCROMBIE &amp; FITCH]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>0.98</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              parent_org_name           children_org_name_list  \\\n",
       "3                    +MARTINS                     [SAN MARINA]   \n",
       "8                   111 SOUTH                      [1&1 IONOS]   \n",
       "13     247 CUSTOMER PVT. LTD.  [24/7 CUSTOMER PRIVATE LIMITED]   \n",
       "18                         3M                             [3M]   \n",
       "57           A. K. ENTERPRISE               [ROUSH ENTERPRISE]   \n",
       "58   A.B. EDWARDS ENTERPRISES           [A. G. EDWARDS & SONS]   \n",
       "70               AAP CO. LTD.          [AAP LEHRERFACHVERLAGE]   \n",
       "87                        ABB                         [ABBVIE]   \n",
       "94                     ABBVIE                         [ABBVIE]   \n",
       "111         ABERCROMBIE FITCH            [ABERCROMBIE & FITCH]   \n",
       "\n",
       "     match_confidence_score match_confidence  jaro_func_score  \\\n",
       "3                  0.750000           MEDIUM             0.78   \n",
       "8                  0.769231           MEDIUM             0.67   \n",
       "13                 0.843750           MEDIUM             0.89   \n",
       "18                 1.000000             HIGH             1.00   \n",
       "57                 0.812500           MEDIUM             0.79   \n",
       "58                 0.769231           MEDIUM             0.73   \n",
       "70                 0.900000             HIGH             0.73   \n",
       "87                 0.750000           MEDIUM             0.88   \n",
       "94                 1.000000             HIGH             1.00   \n",
       "111                1.000000             HIGH             0.98   \n",
       "\n",
       "     total_chars_positions  consecutive_chars  sequence_matcher_ratio  \\\n",
       "3                     10.0                3.0                    0.56   \n",
       "8                      9.0                2.0                    0.44   \n",
       "13                    29.0               12.0                    0.78   \n",
       "18                     2.0                2.0                    1.00   \n",
       "57                    16.0               11.0                    0.69   \n",
       "58                    20.0               10.0                    0.64   \n",
       "70                    21.0                4.0                    0.30   \n",
       "87                     6.0                3.0                    0.67   \n",
       "94                     6.0                6.0                    1.00   \n",
       "111                   19.0               12.0                    0.94   \n",
       "\n",
       "     count_same_position  count_total_unique_chars  count_common_chars  \\\n",
       "3                    0.0                      15.0                 6.0   \n",
       "8                    4.0                      14.0                 4.0   \n",
       "13                   3.0                      36.0                16.0   \n",
       "18                   2.0                       4.0                 2.0   \n",
       "57                  11.0                      22.0                 8.0   \n",
       "58                   2.0                      25.0                 9.0   \n",
       "70                   4.0                      20.0                 5.0   \n",
       "87                   3.0                       7.0                 2.0   \n",
       "94                   6.0                      10.0                 5.0   \n",
       "111                 12.0                      25.0                12.0   \n",
       "\n",
       "     percent_matched  percent_same_position  \n",
       "3               0.40                   0.00  \n",
       "8               0.29                   0.44  \n",
       "13              0.44                   0.10  \n",
       "18              0.50                   1.00  \n",
       "57              0.36                   0.69  \n",
       "58              0.36                   0.10  \n",
       "70              0.25                   0.19  \n",
       "87              0.29                   0.50  \n",
       "94              0.50                   1.00  \n",
       "111             0.48                   0.63  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def total_chars(row):\n",
    "\n",
    "    results0 = []\n",
    "    results1 = []\n",
    "    results2 = []\n",
    "    results3 = []\n",
    "    results4 = []\n",
    "    results5 = []\n",
    "    \n",
    "    p = row['parent_org_name'].lower()\n",
    "    for i in row['children_org_name_list']:\n",
    "        \n",
    "        t = i.lower()\n",
    "        \n",
    "        dict1 = Counter(p)\n",
    "        dict2 = Counter(t)\n",
    "        \n",
    "        commonDict = dict1 & dict2\n",
    "        allChars = len(dict1) + len(dict2)\n",
    "        childCharsPositions = len(t)\n",
    "        \n",
    "        results0.append((i, childCharsPositions)[1]) #totalCharacterPositions\n",
    "        results1.append((i, SequenceMatcher(None, t, p).find_longest_match(0, len(t), 0, len(p))[2])[1]) #consecutiveMatchingChars\n",
    "        results2.append((i, round(SequenceMatcher(None, t, p).ratio(),2))[1]) #sequence_matcher_ratio\n",
    "        results3.append((i, sum(int(k==v) for k,v in zip(t, p)))[1]) #countSamePosition\n",
    "        results4.append((i, allChars)[1])#countTotalUniqueChars\n",
    "        results5.append((i, len(commonDict))[1]) #countCommonChars\n",
    "\n",
    "    return pd.Series([results0, results1, results2, results3, results4, results5])\n",
    "\n",
    "df[['total_chars_positions'\n",
    "    , 'consecutive_chars'\n",
    "    , 'sequence_matcher_ratio'\n",
    "    , 'count_same_position'\n",
    "    , 'count_total_unique_chars'\n",
    "    , 'count_common_chars'\n",
    "   ]]  = df.apply(total_chars, axis=1)\n",
    "\n",
    "df['total_chars_positions'] = df.total_chars_positions.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "df['consecutive_chars'] = df.consecutive_chars.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "df['sequence_matcher_ratio'] = df.sequence_matcher_ratio.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "df['count_same_position'] = df.count_same_position.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "df['count_total_unique_chars'] = df.count_total_unique_chars.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "df['count_common_chars'] = df.count_common_chars.apply(lambda x: ', '.join([str(i) for i in x])).astype(float)\n",
    "\n",
    "df['percent_matched'] = round(df['count_common_chars'] / df['count_total_unique_chars'],2)\n",
    "df['percent_same_position'] = round(df['count_same_position'] / df['total_chars_positions'],2)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>parent_org_name</th>\n",
       "      <th>children_org_name_list</th>\n",
       "      <th>ohe_locations</th>\n",
       "      <th>jaro_func_score</th>\n",
       "      <th>sequence_matcher_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+MARTINS</td>\n",
       "      <td>[SAN MARINA]</td>\n",
       "      <td>[0.56, 307, 932, 2823, 3509, 4852, 5348]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111 SOUTH</td>\n",
       "      <td>[1&amp;1 IONOS]</td>\n",
       "      <td>[0.44, 236, 497, 506, 508, 4325, 5109, 5687]</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247 CUSTOMER PVT. LTD.</td>\n",
       "      <td>[24/7 CUSTOMER PRIVATE LIMITED]</td>\n",
       "      <td>[0.78, 81, 172, 215, 424, 537, 569, 593, 1438,...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3M</td>\n",
       "      <td>[3M]</td>\n",
       "      <td>[3, 555]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. K. ENTERPRISE</td>\n",
       "      <td>[ROUSH ENTERPRISE]</td>\n",
       "      <td>[0.69, 98, 156, 417, 423, 658, 1923, 1975, 288...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          parent_org_name           children_org_name_list  \\\n",
       "0                +MARTINS                     [SAN MARINA]   \n",
       "1               111 SOUTH                      [1&1 IONOS]   \n",
       "2  247 CUSTOMER PVT. LTD.  [24/7 CUSTOMER PRIVATE LIMITED]   \n",
       "3                      3M                             [3M]   \n",
       "4        A. K. ENTERPRISE               [ROUSH ENTERPRISE]   \n",
       "\n",
       "                                       ohe_locations jaro_func_score  \\\n",
       "0           [0.56, 307, 932, 2823, 3509, 4852, 5348]            0.78   \n",
       "1       [0.44, 236, 497, 506, 508, 4325, 5109, 5687]            0.67   \n",
       "2  [0.78, 81, 172, 215, 424, 537, 569, 593, 1438,...            0.89   \n",
       "3                                           [3, 555]            1.00   \n",
       "4  [0.69, 98, 156, 417, 423, 658, 1923, 1975, 288...            0.79   \n",
       "\n",
       "  sequence_matcher_ratio  \n",
       "0                   0.56  \n",
       "1                   0.44  \n",
       "2                   0.78  \n",
       "3                   1.00  \n",
       "4                   0.69  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trigram function\n",
    "def split_str(s, N):\n",
    "    rmax = np.clip(len(s)-N, a_min=0, a_max=None)\n",
    "    return [s[0+i:N+i] for i in range(0, rmax+1)]\n",
    "\n",
    "#arrange dfs and cols\n",
    "df = df[['parent_org_name','children_org_name_list','jaro_func_score','sequence_matcher_ratio']]\n",
    "df1 = df[['parent_org_name','jaro_func_score','sequence_matcher_ratio']]\n",
    "df['parent_trigram'] = df['parent_org_name'].apply(lambda x: split_str(x, 3))\n",
    "# del df[['jaro_func_score','sequence_matcher_ratio']]\n",
    "\n",
    "#binarizer option\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "mlb_df = df.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(df.pop('parent_trigram')),\n",
    "                index=df.index,\n",
    "                columns=mlb.classes_))\n",
    "\n",
    "#create numbers as column names\n",
    "mlb_df = mlb_df.rename(columns={x:y for x,y in zip(mlb_df.columns,range(0,len(mlb_df.columns)))})\n",
    "\n",
    "#convert 0,1s to col name\n",
    "values = np.where(mlb_df.eq(1), mlb_df.columns, mlb_df)\n",
    "mlb_df = pd.DataFrame(values, columns=mlb_df.columns)\n",
    "\n",
    "#concat all columns into a list, agg per row, and drop zeros\n",
    "mlb_df['ohe_locations'] = (mlb_df.iloc[:,3:].astype(str)\n",
    " .agg(lambda x: ' '.join(i for i in x if i != '0'), axis=1)\n",
    " .str.split()\n",
    ")\n",
    "\n",
    "#create new db of relevant cols\n",
    "mlb_df = mlb_df[[0,1,'ohe_locations']]\n",
    "\n",
    "#change column names\n",
    "mlb_df.columns = [['parent_org_name','children_org_name_list','ohe_locations']]\n",
    "\n",
    "#add back in the jaro score from df1\n",
    "jaro_func_score = list(df1['jaro_func_score'])\n",
    "sequence_matcher_ratio = list(df1['sequence_matcher_ratio'])\n",
    "mlb_df['jaro_func_score'] = jaro_func_score\n",
    "mlb_df['sequence_matcher_ratio'] = sequence_matcher_ratio\n",
    "\n",
    "mlb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train test split\n",
    "X = mlb_df[mlb_df.columns[3:]].values\n",
    "y = mlb_df[mlb_df.columns[0]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report function and classifiers\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "        y_true=y_test\n",
    "        , y_pred=y_predictions\n",
    "        , labels=np.unique(y_pred)\n",
    "    )\n",
    "\n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_test, \n",
    "            y_pred=y_predictions,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-1] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T\n",
    "\n",
    "classifiers = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB() \n",
      "              precision  recall  f1-score  support\n",
      "0                  0.0     0.0       0.0      0.0\n",
      "1                  0.0     0.0       0.0      0.0\n",
      "2                  0.0     0.0       0.0      0.0\n",
      "3                  0.0     0.0       0.0      0.0\n",
      "4                  0.0     0.0       0.0      0.0\n",
      "...                ...     ...       ...      ...\n",
      "729                0.0     0.0       0.0      0.0\n",
      "730                0.0     0.0       0.0      0.0\n",
      "731                0.0     0.0       0.0      0.0\n",
      "732                0.0     0.0       0.0      0.0\n",
      "avg / total        0.0     0.0       0.0      0.0\n",
      "\n",
      "[734 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() \n",
      "              precision  recall  f1-score  support\n",
      "0                  0.0     0.0       0.0      0.0\n",
      "1                  0.0     0.0       0.0      0.0\n",
      "2                  0.0     0.0       0.0      0.0\n",
      "3                  0.0     0.0       0.0      0.0\n",
      "4                  0.0     0.0       0.0      0.0\n",
      "5                  0.0     0.0       0.0      0.0\n",
      "6                  0.0     0.0       0.0      0.0\n",
      "7                  0.0     0.0       0.0      0.0\n",
      "8                  0.0     0.0       0.0      0.0\n",
      "9                  0.0     0.0       0.0      0.0\n",
      "10                 0.0     0.0       0.0      0.0\n",
      "11                 0.0     0.0       0.0      0.0\n",
      "12                 0.0     0.0       0.0      0.0\n",
      "13                 0.0     0.0       0.0      0.0\n",
      "14                 0.0     0.0       0.0      0.0\n",
      "15                 0.0     0.0       0.0      0.0\n",
      "16                 0.0     0.0       0.0      0.0\n",
      "17                 0.0     0.0       0.0      0.0\n",
      "avg / total        0.0     0.0       0.0      0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/acc48668/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier() \n",
      "              precision  recall  f1-score  support\n",
      "0                  0.0     0.0       0.0      0.0\n",
      "1                  0.0     0.0       0.0      0.0\n",
      "2                  0.0     0.0       0.0      0.0\n",
      "3                  0.0     0.0       0.0      0.0\n",
      "4                  0.0     0.0       0.0      0.0\n",
      "...                ...     ...       ...      ...\n",
      "721                0.0     0.0       0.0      0.0\n",
      "722                0.0     0.0       0.0      0.0\n",
      "723                0.0     0.0       0.0      0.0\n",
      "724                0.0     0.0       0.0      0.0\n",
      "avg / total        0.0     0.0       0.0      0.0\n",
      "\n",
      "[726 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "f, axes = plt.subplots(1, 6, figsize=(20, 5), sharey='row')\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "\n",
    "for i, (key, classifier) in enumerate(classifiers.items()):\n",
    "    y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "    y_predictions = classifier.predict(X_test)\n",
    "    df_class_report = pandas_classification_report(y_true=y_test, y_pred=y_predictions)\n",
    "    print((classifier),'\\n',df_class_report)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cf_matrix)\n",
    "#                                   display_labels=)\n",
    "    disp.plot(ax=axes[i], xticks_rotation=0)\n",
    "    disp.ax_.set_title(key)\n",
    "    disp.im_.colorbar.remove()\n",
    "    disp.ax_.set_xlabel('')\n",
    "    if i!=0:\n",
    "        disp.ax_.set_ylabel('')\n",
    "        \n",
    "f.text(0.4, 0.1, 'Predicted label', ha='left')\n",
    "plt.subplots_adjust(wspace=0.40, hspace=0.1)\n",
    "\n",
    "f.colorbar(disp.im_, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parent df stuff - count unique items in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_org_name</th>\n",
       "      <th>parent_trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+MARTINS 111 SOUTH 247 CUSTOMER PVT. LTD. 3M A...</td>\n",
       "      <td>[+MA, MAR, ART, RTI, TIN, INS, NS , S 1,  11, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     parent_org_name  \\\n",
       "0  +MARTINS 111 SOUTH 247 CUSTOMER PVT. LTD. 3M A...   \n",
       "\n",
       "                                      parent_trigram  \n",
       "0  [+MA, MAR, ART, RTI, TIN, INS, NS , S 1,  11, ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_df = pd.DataFrame(' '.join(df['parent_org_name'].tolist()), columns=['parent_org_name'], index=[0])\n",
    "parent_df['parent_trigram'] = parent_df['parent_org_name'].apply(lambda x: split_str(x, 3))\n",
    "parent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[+MA, MAR, ART, RTI, TIN, INS, NS , S 1,  11, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      parent_trigram\n",
       "0  [+MA, MAR, ART, RTI, TIN, INS, NS , S 1,  11, ..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_df = parent_df[['parent_trigram']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110150"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of trigrams\n",
    "parent_df.parent_trigram.str.len().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent_trigram\n",
       "0             +MA\n",
       "0             MAR\n",
       "0             ART\n",
       "0             RTI\n",
       "0             TIN\n",
       "..            ...\n",
       "0             IRA\n",
       "0             RA \n",
       "0             A S\n",
       "0              S \n",
       "0             S A\n",
       "\n",
       "[110150 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique trigrams\n",
    "parent_explode_df = parent_df['parent_trigram'].explode()\n",
    "parent_explode_df = pd.DataFrame(parent_explode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6473"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_explode_df.parent_trigram.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perent_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-68eb6967ceb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_trigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mperent_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'perent_list' is not defined"
     ]
    }
   ],
   "source": [
    "parent_list = parent_df.parent_trigram.tolist()\n",
    "perent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_list = list(df.parent_org_name)\n",
    "\n",
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factorize option (fastest)\n",
    "v = df.parent_trigram.values\n",
    "l = [len(x) for x in v.tolist()]\n",
    "f, u = pd.factorize(np.concatenate(v))\n",
    "n, m = len(v), u.size\n",
    "i = np.arange(n).repeat(l)\n",
    "\n",
    "dummies = pd.DataFrame(\n",
    "    np.bincount(i * m + f, minlength=n * m).reshape(n, m),\n",
    "    df.index, u\n",
    ")\n",
    "\n",
    "df.drop('parent_trigram', 1).join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies option\n",
    "df.drop('parent_trigram', 1).join(df.parent_trigram.str.join('|').str.get_dummies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all 100k list trigrams on y axis\n",
    "ohe_df = pd.DataFrame(data=df, columns=parent_list)\n",
    "ohe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempts to convert 0,1s to column name\n",
    "mlb_df.loc[:,1:]  * mlb_df.columns[1:].astype(int)\n",
    "for col in mlb_df.columns:\n",
    "    mlb_df.loc[mlb_df[col] == 1, col] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df with all trigrams as columns\n",
    "\n",
    "df1 = df[['parent_org_name']]\n",
    "\n",
    "ohe_df = pd.concat([df1, ohe_df], axis=1, sort=False)\n",
    "ohe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df[['parent_org_name']]).toarray())\n",
    "\n",
    "# merge with main df bridge_df on key values\n",
    "df1 = df.join(enc_df)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df.applymap(type)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fe98ce43a80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_ngrams(parent_list, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CountVectorizer(analyzer='char', ngram_range=(3, 3),\n",
      "                vocabulary=['allallall', 'allallthis', 'allallhappened',\n",
      "                            'allallmore', 'allallor', 'allallless',\n",
      "                            'allthisall', 'allthisthis', 'allthishappened',\n",
      "                            'allthismore', 'allthisor', 'allthisless',\n",
      "                            'allhappenedall', 'allhappenedthis',\n",
      "                            'allhappenedhappened', 'allhappenedmore',\n",
      "                            'allhappenedor', 'allhappenedless', 'allmoreall',\n",
      "                            'allmorethis', 'allmorehappened', 'allmoremore',\n",
      "                            'allmoreor', 'allmoreless', 'allorall', 'allorthis',\n",
      "                            'allorhappened', 'allormore', 'alloror',\n",
      "                            'allorless', ...])\n"
     ]
    }
   ],
   "source": [
    "input_list = ['all', 'this', 'happened', 'more', 'or', 'less']\n",
    "\n",
    "keywords = [''.join(i) for i in itertools.product(input_list, repeat = 3)]\n",
    "vector = CountVectorizer(analyzer='char', ngram_range=(3,3), vocabulary=keywords)\n",
    "tr_test = vector.transform(['word1'])\n",
    "print(tr_test)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df['parent_org_name'] = ohe_df.parent_org_name.astype(str)\n",
    "\n",
    "for c in ohe_df['parent_org_name']:\n",
    "    ohe_df[c] = ohe_df['parent_org_name'].apply(lambda x: int(c in x))\n",
    "    print (ohe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3                           [+MA, MAR, ART, RTI, TIN, INS]\n",
       "8                      [111, 11 , 1 S,  SO, SOU, OUT, UTH]\n",
       "13       [247, 47 , 7 C,  CU, CUS, UST, STO, TOM, OME, ...\n",
       "18                                                    [3M]\n",
       "57       [A. , . K,  K., K. , . E,  EN, ENT, NTE, TER, ...\n",
       "                               ...                        \n",
       "10303    [NAT, ATO, TOM, OMA, MAS, AS , S S,  SC, SCH, ...\n",
       "11965    [RAD, ADI, DIU, IUS, US , S H,  HE, HEA, EAL, ...\n",
       "809      [AME, MER, ERI, RIC, ICA, CAN, AN , N M,  MU, ...\n",
       "840      [AMI, MIX, IXC, XCO, COM, OM , M I,  IN, INC, ...\n",
       "4533                                  [DEV, EVI, VID, IDA]\n",
       "Name: parent_org_name, Length: 5210, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trigram function\n",
    "def split_str(s, N):\n",
    "    rmax = np.clip(len(s)-N, a_min=0, a_max=None)\n",
    "    return [s[0+i:N+i] for i in range(0, rmax+1)]\n",
    "\n",
    "df['parent_org_name'].apply(lambda x: split_str(x, 3))\n",
    "# input_list.apply(lambda x: split_str(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(input, n):\n",
    "    input = input.split(' ')\n",
    "    output = []\n",
    "    for i in range(len(input)-n+1):\n",
    "        output.append(input[i:i+n])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b04abe1d24ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_org_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-d1cb9f32e01b>\u001b[0m in \u001b[0;36mngrams\u001b[0;34m(input, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "ngrams(df.parent_org_name, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f9bd6102b40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_ngrams(input_list,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize('this is a string')\n",
    "my_bigrams = nltk.bigrams(words)\n",
    "my_trigrams = nltk.trigrams(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object bigrams at 0x7fe9a7255890>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from itertools import islice\n",
    "\n",
    "def ngrams(message, n=1):\n",
    "    it = iter(message.split())\n",
    "    window = deque(islice(it, n), maxlen=n)\n",
    "    yield tuple(window)\n",
    "    for item in it:\n",
    "        window.append(item)\n",
    "        yield tuple(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x7fe9a7255120>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(input_list,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "text = \"Hi How are you? i am fine and you\"\n",
    "token=nltk.word_tokenize(text)\n",
    "bigrams=ngrams(token,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x7fe9a7278ac0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3                                  +MARTINS\\n8                                 111 SOUTH\\n13                   247 CUSTOMER PVT. LTD.\\n18                                       3M\\n57                         A. K. ENTERPRISE\\n                        ...                \\n10303               NATOMAS SCHOOL DISTRICT\\n11965                     RADIUS HEALTH INC\\n809      AMERICAN MUSEUM OF NATURAL HISTORY\\n840                            AMIXCOM INC.\\n4533                                 DEVIDA\\nName: parent_org_name, Length: 5210, dtype: object'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_list = str(df.parent_org_name)\n",
    "parent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_org_name_string = pd.DataFrame(' '.join(df['parent_org_name'].tolist()), columns=['parent_org_name'], index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_org_name</th>\n",
       "      <th>parent_trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+MARTINS 111 SOUTH 247 CUSTOMER PVT. LTD. 3M A...</td>\n",
       "      <td>[+MA, MAR, ART, RTI, TIN, INS, NS , S 1,  11, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     parent_org_name  \\\n",
       "0  +MARTINS 111 SOUTH 247 CUSTOMER PVT. LTD. 3M A...   \n",
       "\n",
       "                                      parent_trigram  \n",
       "0  [+MA, MAR, ART, RTI, TIN, INS, NS , S 1,  11, ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_org_name_string = pd.DataFrame(' '.join(df['parent_org_name'].tolist()), columns=['parent_org_name'], index=[0])\n",
    "parent_org_name_string['parent_trigram'] = parent_org_name_string['parent_org_name'].apply(lambda x: split_str(x, 3))\n",
    "parent_org_name_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original df shape: \\n', df.shape)\n",
    "print('')\n",
    "\n",
    "print('dtypes: \\n', df.dtypes)\n",
    "print('')\n",
    "\n",
    "print('original match confidence bins values counts: \\n', df.match_confidence.value_counts())\n",
    "print('')\n",
    "\n",
    "#create df of just medium and high\n",
    "df1 = df[df['match_confidence'].isin(['MEDIUM','HIGH'])]\n",
    "print('high low df shape: \\n', df1.shape)\n",
    "print('high and low df value counts: \\n', df1.match_confidence.value_counts())\n",
    "print('')\n",
    "\n",
    "#create low df\n",
    "df2 = df[df['match_confidence'] == 'LOW']\n",
    "print('low df shape: \\n', df2.shape)\n",
    "print('')\n",
    "\n",
    "#create sample of 2k rows of low df\n",
    "df2 = df2.sample(2000)\n",
    "\n",
    "#concat dfs\n",
    "frames = [df1,df2]\n",
    "df = pd.concat(frames)\n",
    "print('new df shape with sample of 2k low rows: \\n', df.shape)\n",
    "print('new df value counts: \\n', df.match_confidence.value_counts())\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
